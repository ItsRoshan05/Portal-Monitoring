{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataSet/datasetTitle/titleLabel1000.csv')\n",
    "# df['title'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype(\"int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def casefolding(kalimat):\n",
    "    # kalimat = kalimat.translate(str.maketrans(' ',' ',string.punctuation))\n",
    "    kalimat = kalimat.strip()\n",
    "    kalimat = kalimat.lower()\n",
    "    kalimat = re.sub(r'[|?|$|.|!_:\")(-+,)]','', kalimat)\n",
    "    # kalimat = re.sub('<.*>',' ',kalimat)\n",
    "    # kalimat = re.sub('[^a-zA-Z]',' ', kalimat)\n",
    "    # kalimat = re.sub(r\"\\b[a-aZ-Z]\\b\",\" \", kalimat)\n",
    "    # kalimat = re.sub(r'\\b\\w\\b', '', kalimat)\n",
    "    # kalimat = re.sub(\"\\n\",\" \", kalimat)\n",
    "    return kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manusia diterkam beruang'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['title'] = df['title'].apply(casefolding)\n",
    "df['title'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "regexp = RegexpTokenizer(r'\\w+|$[0-9]+|\\S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = df[\"title\"].apply(regexp.tokenize)\n",
    "df.insert(df.columns.get_loc(\"label\"),\"Token\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manusia', 'diterkam', 'beruang']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Token'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "crft = CRFTagger()\n",
    "crft.set_model_file('../resource/all_indo_man_tag_corpus_model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = crft.tag_sents(df.Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(df.columns.get_loc(\"label\"),\"tag\", tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('museum', 'NN'),\n",
       " ('subang', 'NN'),\n",
       " ('masih', 'MD'),\n",
       " ('kurang', 'RB'),\n",
       " ('pengunjung', 'VB')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag'].iloc[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StopWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AdmiN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AdmiN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading CRF++-0.58-cp37-cp37m-win_amd64.whl: Package\n",
      "[nltk_data]     'CRF++-0.58-cp37-cp37m-win_amd64.whl' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Error loading CRF++-0.58-cp38-cp38-win_amd64.whl: Package\n",
      "[nltk_data]     'CRF++-0.58-cp38-cp38-win_amd64.whl' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import CRFTagger\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"CRF++-0.58-cp37-cp37m-win_amd64.whl\")\n",
    "nltk.download(\"CRF++-0.58-cp38-cp38-win_amd64.whl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_word_by_tag(text):\n",
    "    # Tokenisasi kalimat\n",
    "    # sentences = sent_tokenize(text, language='indonesian')\n",
    "    sentence = text\n",
    "    result = []\n",
    "    \n",
    "    # Membuat CRF Tagger\n",
    "    tagger = CRFTagger()\n",
    "    tagger.set_model_file('../resource/all_indo_man_tag_corpus_model.crf.tagger')  # Gantilah path dengan lokasi model POS tagger untuk bahasa Indonesia\n",
    "    \n",
    "    for sentence in sentence:\n",
    "        # Tokenisasi kata-kata dalam kalimat\n",
    "        words = word_tokenize(sentence)\n",
    "        \n",
    "        stopword = stopwords.words('indonesian')\n",
    "        txt_stopword = pd.read_csv('../resource/stopword.txt', names=['stopword'], header=None)\n",
    "        stopword.extend(['wkwk','hahahaha','haha','yang','yoi','yoyoy', 'mm', 'mk', 'bandung', 'subang','wartakinico','galamedianews','rp','$'])\n",
    "        stopword.extend(txt_stopword[\"stopword\"][0].split('\\n'))\n",
    "        stopword = set(stopword)\n",
    "        # Menghapus stop words berdasarkan tag\n",
    "        tagged_words = tagger.tag(words)\n",
    "        filtered_words = [word for word, tag in tagged_words if word.lower() not in stopword or tag.startswith(('NN', 'RB'))]\n",
    "        \n",
    "        # Menggabungkan kata-kata yang tersaring untuk membentuk kalimat baru\n",
    "        filtered_sentence = ' '.join(filtered_words)\n",
    "        \n",
    "        # Menambahkan kalimat yang telah dihapus stop words ke hasil akhir\n",
    "        result.append(filtered_sentence)\n",
    "    \n",
    "    # Menggabungkan kalimat menjadi teks lengkap\n",
    "    final_text = ' '.join(result)\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordByTag = df['Token'].apply(remove_stop_word_by_tag)\n",
    "df.insert(df.columns.get_loc(\"label\"),\"stopwordByTag\", stopwordByTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ditanya soal pengembalian kerugian negara dinas pupr bangkalan sebut bpk kurang update\n"
     ]
    }
   ],
   "source": [
    "print(df['title'].iloc[982])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ditanya soal pengembalian kerugian negara dinas pupr bangkalan  bpk kurang update\n"
     ]
    }
   ],
   "source": [
    "print(df['stopwordByTag'].iloc[982])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ditanya', 'VB'), ('soal', 'NN'), ('pengembalian', 'NN'), ('kerugian', 'NN'), ('negara', 'NN'), ('dinas', 'NN'), ('pupr', 'NN'), ('bangkalan', 'NN'), ('sebut', 'VB'), ('bpk', 'NN'), ('kurang', 'RB'), ('update', 'FW')]\n"
     ]
    }
   ],
   "source": [
    "print(df['tag'].iloc[982])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AdmiN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk as nk \n",
    "nk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stopword = stopwords.words('indonesian')\n",
    "# txt_stopword = pd.read_csv('../resource/stopword.txt', names=['stopword'], header=None)\n",
    "# stopword.extend(['wkwk','hahahaha','haha','yang','yoi','yoyoy', 'mm', 'mk', 'bandung', 'subang','wartakinico','galamedianews','rp','$'])\n",
    "# stopword.extend(txt_stopword[\"stopword\"][0].split('\\n'))\n",
    "# stopword = set(stopword)\n",
    "\n",
    "# def stopwords(text):\n",
    "#     text = [word for word in text if word not in stopword]\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword = df['Token'].apply(stopwords)\n",
    "# df.insert(df.columns.get_loc(\"label\"),\"stopword\", stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['title', 'stopword']].iloc[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pilih Salah satu dari metode stemming di bawah, Menggunakan join atau tanpa menggunakan join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsi Pertama: Melakukan stemming dan meReturn hasilnya dengan join \n",
    "def stemmingWithJoin(konten):\n",
    "    words = word_tokenize(konten)\n",
    "    do = []\n",
    "    for w in words:\n",
    "        dt = stemmer.stem(w)\n",
    "        do.append(dt)\n",
    "    \n",
    "    d_clean = []\n",
    "    d_clean = \" \".join(do)\n",
    "    return d_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsi Kedua : Melakukan stemming dengan tidak mereturnnya dengan join\n",
    "\n",
    "# def stemmed_wrapper(term):\n",
    "#     return stemmer.stem(term)\n",
    "\n",
    "# term_dict = {}\n",
    "\n",
    "# kata = df['stopword']\n",
    "# for doc in kata:\n",
    "#     for term in doc:\n",
    "#         if term not in term_dict:\n",
    "#             term_dict[term] = ''\n",
    "    \n",
    "    \n",
    "# for term in term_dict:\n",
    "#     term_dict[term] = stemmed_wrapper(term)\n",
    "\n",
    "\n",
    "# def get_stemmed_term(doc):\n",
    "#     return [term_dict[term] for term in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan opsi pertama\n",
    "stemmed = df['stopwordByTag'].apply(stemmingWithJoin)\n",
    "df.insert(df.columns.get_loc(\"label\"),\"stemmed\", stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menggunakan Opsi ke dua\n",
    "\n",
    "# stemmed = df['stopword'].apply(get_stemmed_term)\n",
    "# df.insert(df.columns.get_loc(\"label\"),\"stemmed\", stemmed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Token</th>\n",
       "      <th>tag</th>\n",
       "      <th>stopwordByTag</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngatiyana terjun langsung menemui warga menamp...</td>\n",
       "      <td>[ngatiyana, terjun, langsung, menemui, warga, ...</td>\n",
       "      <td>[(ngatiyana, SC), (terjun, VB), (langsung, RB)...</td>\n",
       "      <td>ngatiyana terjun langsung menemui warga menamp...</td>\n",
       "      <td>ngatiyana terjun langsung temu warga tampung a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manusia diterkam beruang</td>\n",
       "      <td>[manusia, diterkam, beruang]</td>\n",
       "      <td>[(manusia, NN), (diterkam, NN), (beruang, NN)]</td>\n",
       "      <td>manusia diterkam beruang</td>\n",
       "      <td>manusia terkam beruang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>puluhan rumah di perum griya zavira cilawu ter...</td>\n",
       "      <td>[puluhan, rumah, di, perum, griya, zavira, cil...</td>\n",
       "      <td>[(puluhan, CD), (rumah, NN), (di, IN), (perum,...</td>\n",
       "      <td>puluhan rumah  perum griya zavira cilawu teran...</td>\n",
       "      <td>puluh rumah perum griya zavira cilawu ancam ba...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prakiraan cuaca kota-kota besar di indonesia u...</td>\n",
       "      <td>[prakiraan, cuaca, kota, -, kota, besar, di, i...</td>\n",
       "      <td>[(prakiraan, NN), (cuaca, NN), (kota, NN), (-,...</td>\n",
       "      <td>prakiraan cuaca kota - kota   indonesia  senin...</td>\n",
       "      <td>prakira cuaca kota - kota indonesia senin 25 j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kurang dari 24 jam pelaku pembunuh remaja dici...</td>\n",
       "      <td>[kurang, dari, 24, jam, pelaku, pembunuh, rema...</td>\n",
       "      <td>[(kurang, RB), (dari, IN), (24, CD), (jam, NN)...</td>\n",
       "      <td>kurang  24 jam pelaku pembunuh remaja diciduk ...</td>\n",
       "      <td>kurang 24 jam laku bunuh remaja ciduk saat cob...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0  ngatiyana terjun langsung menemui warga menamp...  \\\n",
       "1                           manusia diterkam beruang   \n",
       "2  puluhan rumah di perum griya zavira cilawu ter...   \n",
       "3  prakiraan cuaca kota-kota besar di indonesia u...   \n",
       "4  kurang dari 24 jam pelaku pembunuh remaja dici...   \n",
       "\n",
       "                                               Token   \n",
       "0  [ngatiyana, terjun, langsung, menemui, warga, ...  \\\n",
       "1                       [manusia, diterkam, beruang]   \n",
       "2  [puluhan, rumah, di, perum, griya, zavira, cil...   \n",
       "3  [prakiraan, cuaca, kota, -, kota, besar, di, i...   \n",
       "4  [kurang, dari, 24, jam, pelaku, pembunuh, rema...   \n",
       "\n",
       "                                                 tag   \n",
       "0  [(ngatiyana, SC), (terjun, VB), (langsung, RB)...  \\\n",
       "1     [(manusia, NN), (diterkam, NN), (beruang, NN)]   \n",
       "2  [(puluhan, CD), (rumah, NN), (di, IN), (perum,...   \n",
       "3  [(prakiraan, NN), (cuaca, NN), (kota, NN), (-,...   \n",
       "4  [(kurang, RB), (dari, IN), (24, CD), (jam, NN)...   \n",
       "\n",
       "                                       stopwordByTag   \n",
       "0  ngatiyana terjun langsung menemui warga menamp...  \\\n",
       "1                           manusia diterkam beruang   \n",
       "2  puluhan rumah  perum griya zavira cilawu teran...   \n",
       "3  prakiraan cuaca kota - kota   indonesia  senin...   \n",
       "4  kurang  24 jam pelaku pembunuh remaja diciduk ...   \n",
       "\n",
       "                                             stemmed  label  \n",
       "0  ngatiyana terjun langsung temu warga tampung a...      1  \n",
       "1                             manusia terkam beruang      0  \n",
       "2  puluh rumah perum griya zavira cilawu ancam ba...      2  \n",
       "3  prakira cuaca kota - kota indonesia senin 25 j...      0  \n",
       "4  kurang 24 jam laku bunuh remaja ciduk saat cob...      2  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(sentence)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    lemmatized_sentence = ' '.join(lemmatized_words)\n",
    "    return lemmatized_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "llema = df['stopwordByTag'].apply(lemmatize_sentence)\n",
    "df.insert(df.columns.get_loc(\"label\"),\"lemma\", llema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export File hasil Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataSet/datasetTitle/titleClean1000_3.csv', header=True , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"mysql+pymysql://{0}:{1}@{2}:{3}/{4}\".format(\"root\", \"\", \"127.0.0.1\", 3306, 'db_sma2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ceked'] = df['title'] == df['stopwordByTag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Token</th>\n",
       "      <th>tag</th>\n",
       "      <th>stopwordByTag</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemma</th>\n",
       "      <th>label</th>\n",
       "      <th>ceked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngatiyana terjun langsung menemui warga menamp...</td>\n",
       "      <td>[ngatiyana, terjun, langsung, menemui, warga, ...</td>\n",
       "      <td>[(ngatiyana, SC), (terjun, VB), (langsung, RB)...</td>\n",
       "      <td>ngatiyana terjun langsung menemui warga menamp...</td>\n",
       "      <td>ngatiyana terjun langsung temu warga tampung a...</td>\n",
       "      <td>ngatiyana terjun langsung menemui warga menamp...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manusia diterkam beruang</td>\n",
       "      <td>[manusia, diterkam, beruang]</td>\n",
       "      <td>[(manusia, NN), (diterkam, NN), (beruang, NN)]</td>\n",
       "      <td>manusia diterkam beruang</td>\n",
       "      <td>manusia terkam beruang</td>\n",
       "      <td>manusia diterkam beruang</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>puluhan rumah di perum griya zavira cilawu ter...</td>\n",
       "      <td>[puluhan, rumah, di, perum, griya, zavira, cil...</td>\n",
       "      <td>[(puluhan, CD), (rumah, NN), (di, IN), (perum,...</td>\n",
       "      <td>puluhan rumah  perum griya zavira cilawu teran...</td>\n",
       "      <td>puluh rumah perum griya zavira cilawu ancam ba...</td>\n",
       "      <td>puluhan rumah perum griya zavira cilawu teranc...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prakiraan cuaca kota-kota besar di indonesia u...</td>\n",
       "      <td>[prakiraan, cuaca, kota, -, kota, besar, di, i...</td>\n",
       "      <td>[(prakiraan, NN), (cuaca, NN), (kota, NN), (-,...</td>\n",
       "      <td>prakiraan cuaca kota - kota   indonesia  senin...</td>\n",
       "      <td>prakira cuaca kota - kota indonesia senin 25 j...</td>\n",
       "      <td>prakiraan cuaca kota - kota indonesia senin 25...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kurang dari 24 jam pelaku pembunuh remaja dici...</td>\n",
       "      <td>[kurang, dari, 24, jam, pelaku, pembunuh, rema...</td>\n",
       "      <td>[(kurang, RB), (dari, IN), (24, CD), (jam, NN)...</td>\n",
       "      <td>kurang  24 jam pelaku pembunuh remaja diciduk ...</td>\n",
       "      <td>kurang 24 jam laku bunuh remaja ciduk saat cob...</td>\n",
       "      <td>kurang 24 jam pelaku pembunuh remaja diciduk s...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0  ngatiyana terjun langsung menemui warga menamp...  \\\n",
       "1                           manusia diterkam beruang   \n",
       "2  puluhan rumah di perum griya zavira cilawu ter...   \n",
       "3  prakiraan cuaca kota-kota besar di indonesia u...   \n",
       "4  kurang dari 24 jam pelaku pembunuh remaja dici...   \n",
       "\n",
       "                                               Token   \n",
       "0  [ngatiyana, terjun, langsung, menemui, warga, ...  \\\n",
       "1                       [manusia, diterkam, beruang]   \n",
       "2  [puluhan, rumah, di, perum, griya, zavira, cil...   \n",
       "3  [prakiraan, cuaca, kota, -, kota, besar, di, i...   \n",
       "4  [kurang, dari, 24, jam, pelaku, pembunuh, rema...   \n",
       "\n",
       "                                                 tag   \n",
       "0  [(ngatiyana, SC), (terjun, VB), (langsung, RB)...  \\\n",
       "1     [(manusia, NN), (diterkam, NN), (beruang, NN)]   \n",
       "2  [(puluhan, CD), (rumah, NN), (di, IN), (perum,...   \n",
       "3  [(prakiraan, NN), (cuaca, NN), (kota, NN), (-,...   \n",
       "4  [(kurang, RB), (dari, IN), (24, CD), (jam, NN)...   \n",
       "\n",
       "                                       stopwordByTag   \n",
       "0  ngatiyana terjun langsung menemui warga menamp...  \\\n",
       "1                           manusia diterkam beruang   \n",
       "2  puluhan rumah  perum griya zavira cilawu teran...   \n",
       "3  prakiraan cuaca kota - kota   indonesia  senin...   \n",
       "4  kurang  24 jam pelaku pembunuh remaja diciduk ...   \n",
       "\n",
       "                                             stemmed   \n",
       "0  ngatiyana terjun langsung temu warga tampung a...  \\\n",
       "1                             manusia terkam beruang   \n",
       "2  puluh rumah perum griya zavira cilawu ancam ba...   \n",
       "3  prakira cuaca kota - kota indonesia senin 25 j...   \n",
       "4  kurang 24 jam laku bunuh remaja ciduk saat cob...   \n",
       "\n",
       "                                               lemma  label  ceked  \n",
       "0  ngatiyana terjun langsung menemui warga menamp...      1   True  \n",
       "1                           manusia diterkam beruang      0   True  \n",
       "2  puluhan rumah perum griya zavira cilawu teranc...      2  False  \n",
       "3  prakiraan cuaca kota - kota indonesia senin 25...      0  False  \n",
       "4  kurang 24 jam pelaku pembunuh remaja diciduk s...      2  False  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title','stopwordByTag','ceked','lemma','stemmed',]].to_sql('testing_0.1.1', con=url, index=False, if_exists = 'replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
